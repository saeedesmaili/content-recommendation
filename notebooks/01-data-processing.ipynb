{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import tqdm\n",
    "import requests\n",
    "from pydantic import BaseModel, HttpUrl, field_serializer\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import tiktoken\n",
    "from openai import OpenAI\n",
    "from sqlite_utils import Database\n",
    "\n",
    "load_dotenv()\n",
    "db = Database(\"data.db\")\n",
    "articles_db = db[\"article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article(BaseModel):\n",
    "    pocket_item_id: int\n",
    "    given_url: HttpUrl\n",
    "    resolved_url: HttpUrl\n",
    "    title: str\n",
    "    time_added: datetime\n",
    "    word_count: int\n",
    "    domain: str\n",
    "    text: str | None = None\n",
    "    summary: str | None = None\n",
    "    summary_attempted_message: str | None = None\n",
    "\n",
    "    @field_serializer(\"given_url\", \"resolved_url\")\n",
    "    def serialize_url(self, url: HttpUrl) -> str:\n",
    "        return str(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. List of likes articles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the items already saved in the sqlite db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select *\n",
    "from article\n",
    "\"\"\"\n",
    "results = db.query(q) # generator\n",
    "articles = [Article(**item) for item in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Pocket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "POCKET_HEADERS = {\n",
    "    \"Content-Type\": \"application/json; charset=UTF8\",\n",
    "    \"X-Accept\": \"application/json\",\n",
    "}\n",
    "POCKET_CONSUMER_KEY = os.getenv(\"POCKET_CONSUMER_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authorize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skip to `Read from .env file` if you have authorized previously. Otherwise:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"consumer_key\": POCKET_CONSUMER_KEY, \"redirect_uri\": \"https://127.0.0.1\"}\n",
    "url = \"https://getpocket.com/v3/oauth/request\"\n",
    "r = requests.request(\"Post\", url=url, headers=POCKET_HEADERS, json=data)\n",
    "# {\"code\": \"abcd-1234-abcd-1234\", 'state': None}\n",
    "\n",
    "POCKET_CODE = r.json()[\"code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `your-code` in the following url with the code value you get, and open the url in your browser, grant access, close the tab, then get back here and run the next cell to get access token:\n",
    "\n",
    "https://getpocket.com/auth/authorize?request_token=your-code&redirect_uri=https://127.0.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"consumer_key\": POCKET_CONSUMER_KEY, \"code\": POCKET_CODE}\n",
    "url = \"https://getpocket.com/v3/oauth/authorize\"\n",
    "r = requests.request(\"Post\", url=url, headers=POCKET_HEADERS, json=data)\n",
    "# {\"access_token\": \"efgh-1234-efgh-1234\", \"username\": \"your-username\"}\n",
    "\n",
    "POCKET_ACCESS_TOKEN = r.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the `access_token` to `.env` file, so you can skip the authorization steps above next times and just use the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read from `.env` file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "POCKET_ACCESS_TOKEN = os.getenv(\"POCKET_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching more articles... 500 / 3784\n",
      "Fetching more articles... 1000 / 3784\n",
      "Fetching more articles... 1500 / 3784\n",
      "Fetching more articles... 2000 / 3784\n",
      "Error processing item 3945908435: 1 validation error for Article\n",
      "resolved_url\n",
      "  Input should be a valid URL, input is empty [type=url_parsing, input_value='', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/url_parsing\n",
      "Fetching more articles... 2500 / 3784\n",
      "Fetching more articles... 3000 / 3784\n",
      "Fetching more articles... 3500 / 3784\n",
      "Fetched 4000 articles\n",
      "3783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Article(pocket_item_id=5598506, given_url=HttpUrl('https://nat.org/'), resolved_url=HttpUrl('http://nat.org/'), title='Nat Friedman', time_added=datetime.datetime(2025, 1, 15, 11, 20, 58), word_count=451, domain='nat.org', text=None, summary=None, summary_attempted_message=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pocket_items(state: str = \"archive\") -> list[Article]:\n",
    "    \"\"\"\n",
    "    Get all items archive in pocket\n",
    "    \"\"\"\n",
    "    pocket_items = []\n",
    "    count = 500\n",
    "    offset = 0\n",
    "    while True:\n",
    "        payload = {\n",
    "            \"consumer_key\": POCKET_CONSUMER_KEY,\n",
    "            \"access_token\": POCKET_ACCESS_TOKEN,\n",
    "            \"state\": state,\n",
    "            \"sort\": \"newest\",\n",
    "            \"count\": count,\n",
    "            \"offset\": offset,\n",
    "            \"detailType\": \"complete\",\n",
    "            \"total\": \"1\",  ## total number of archived articles\n",
    "        }\n",
    "\n",
    "        url = \"https://getpocket.com/v3/get\"\n",
    "        r = requests.request(\"Post\", url=url, headers=POCKET_HEADERS, json=payload)\n",
    "\n",
    "        for item in r.json()[\"list\"]:\n",
    "            pocket_item = r.json()[\"list\"][item]\n",
    "            try:\n",
    "                pocket_items.append(\n",
    "                    Article(\n",
    "                        pocket_item_id=int(pocket_item[\"item_id\"]),\n",
    "                        given_url=pocket_item[\"given_url\"],\n",
    "                        resolved_url=pocket_item[\"resolved_url\"],\n",
    "                        title=pocket_item[\"resolved_title\"],\n",
    "                        time_added=datetime.fromtimestamp(\n",
    "                            int(pocket_item[\"time_added\"])\n",
    "                        ),\n",
    "                        word_count=int(pocket_item[\"word_count\"]),\n",
    "                        domain=pocket_item.get(\"domain_metadata\", {}).get(\"name\", \"\"),\n",
    "                    )\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing item {pocket_item['item_id']}: {e}\")\n",
    "                continue\n",
    "\n",
    "        if int(r.json()[\"total\"]) > count + offset:\n",
    "            print(f\"Fetching more articles... {count + offset} / {r.json()['total']}\")\n",
    "            offset += count\n",
    "        else:\n",
    "            print(f\"Fetched {offset + count} articles\")\n",
    "            break\n",
    "\n",
    "    return pocket_items\n",
    "\n",
    "\n",
    "pocket_items = get_pocket_items()\n",
    "print(len(pocket_items))\n",
    "pocket_items[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the articles data in the sqlite db:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table article (pocket_item_id, given_url, resolved_url, title, time_added, word_count, domain, text, summary, summary_attempted_message)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_db.insert_all(\n",
    "    [item.model_dump() for item in pocket_items], pk=\"pocket_item_id\", ignore=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also storing the articles data in a pandas dataframe, just to be able to explore the data if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pocket_item_id</th>\n",
       "      <th>given_url</th>\n",
       "      <th>resolved_url</th>\n",
       "      <th>title</th>\n",
       "      <th>time_added</th>\n",
       "      <th>word_count</th>\n",
       "      <th>domain</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_attempted_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5598506</td>\n",
       "      <td>https://nat.org/</td>\n",
       "      <td>http://nat.org/</td>\n",
       "      <td>Nat Friedman</td>\n",
       "      <td>2025-01-15 11:20:58</td>\n",
       "      <td>451</td>\n",
       "      <td>nat.org</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17661119</td>\n",
       "      <td>https://www.jofreeman.com/joreen/tyranny.htm</td>\n",
       "      <td>https://www.jofreeman.com/joreen/tyranny.htm</td>\n",
       "      <td>THE TYRANNY of STRUCTURELESSNESS</td>\n",
       "      <td>2025-01-24 00:25:45</td>\n",
       "      <td>6486</td>\n",
       "      <td>www.jofreeman.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pocket_item_id                                     given_url  \\\n",
       "0         5598506                              https://nat.org/   \n",
       "1        17661119  https://www.jofreeman.com/joreen/tyranny.htm   \n",
       "\n",
       "                                   resolved_url  \\\n",
       "0                               http://nat.org/   \n",
       "1  https://www.jofreeman.com/joreen/tyranny.htm   \n",
       "\n",
       "                              title          time_added  word_count  \\\n",
       "0                      Nat Friedman 2025-01-15 11:20:58         451   \n",
       "1  THE TYRANNY of STRUCTURELESSNESS 2025-01-24 00:25:45        6486   \n",
       "\n",
       "              domain  text summary summary_attempted_message  \n",
       "0            nat.org  None    None                      None  \n",
       "1  www.jofreeman.com  None    None                      None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([article.model_dump() for article in pocket_items])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract texts using `r.jina.ai`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use [Jina Reader](https://jina.ai/reader/) to extract the text of the saved articles. Its free API is limited to 20 requests per minute, but you can pay and use an API key to get 200 requests per minute limit. Visit [their website](https://jina.ai/) to get an API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "JINA_API_KEY = os.getenv(\"JINA_API_KEY\")\n",
    "\n",
    "## not used currently\n",
    "def count_tokens(text: str) -> int:\n",
    "    ## using gpt-4o tokenizer just to get an estimate\n",
    "    return len(tiktoken.encoding_for_model(\"gpt-4o\").encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_text(url: str, with_api_key: bool = True) -> str:\n",
    "    request_url = f\"https://r.jina.ai/{url}\"\n",
    "\n",
    "    if with_api_key:\n",
    "        headers = {\"Authorization\": f\"Bearer {JINA_API_KEY}\", \"X-No-Cache\": \"true\"}\n",
    "    else:\n",
    "        headers = {\"X-No-Cache\": \"true\"}\n",
    "\n",
    "    r = requests.get(request_url, headers=headers)\n",
    "\n",
    "    if r.status_code == 402:\n",
    "        raise Exception(\"Token limit reached.\")\n",
    "    if r.status_code == 422:\n",
    "        print(f\"422 error, probably an invalid url: {url}\")\n",
    "        return \"Error\"\n",
    "    if r.status_code != 200:\n",
    "        print(f\"Error fetching {url}: {r.status_code}, sleeping for 10 seconds ...\")\n",
    "        print(r.text)\n",
    "        time.sleep(10)\n",
    "        return get_url_text(url, with_api_key=with_api_key)\n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3527, processing https://danielwirtz/blog/bottom-up-note-taking-in-capacities ...\n",
      "422 error, probably an invalid url: https://danielwirtz/blog/bottom-up-note-taking-in-capacities\n",
      "3558, processing https://www.reddit.com/r/Garmin/comments/1hkjty5/i_walked_100k_steps_in_24hrs/?share_id=1wgtlO8zlZBkSB0lLPRqY&utm_content=1&utm_medium=android_app&utm_name=androidcss&utm_source=share&utm_term=2 ...\n",
      "3564, processing http://blog.rongarret.info/2024/12/i-have-failed-now-what.html ...\n",
      "3585, processing https://raymondtukpe.com/exploring-alternatives-to-uuidv4-enter-ulids.html ...\n",
      "3615, processing https://www.david-dahan.com/blog/comparing-fastapi-and-django ...\n",
      "3645, processing https://nmn.gl/blog/blog/ai-senior-developer ...\n",
      "3676, processing https://nikkin.dev/blog/llm-entropy.html ...\n",
      "3680, processing https://blog.anj.ai/2025/01/llm-token-generation-probabilities.html ...\n",
      "3682, processing https://danielwirtz/blog/utrecht-ultra-2024-race-report ...\n",
      "422 error, probably an invalid url: https://danielwirtz/blog/utrecht-ultra-2024-race-report\n",
      "3683, processing https://www.reddit.com/r/Entrepreneurs/comments/1hvi7l4/i_tested_reddit_content_marketing_for_a_year_got/?share_id=w5oEnQiUKBH92lXSxdAsZ&utm_content=1&utm_medium=android_app&utm_name=androidcss&utm_source=share&utm_term=2 ...\n",
      "3692, processing https://taoofmac.com/space/blog/2025/01/12/1730 ...\n",
      "3694, processing https://rustle.ca/posts/articles/work-from-home-lighting ...\n",
      "3695, processing https://data-people-group.github.io/blogs/2025/01/13/docwrangler/ ...\n",
      "3696, processing https://mlops.systems/posts/2025-01-13-assembling-the-prompt:-notes-on-prompt-engineering-for-llms-ch-6.html ...\n",
      "3698, processing https://olup-blog.pages.dev/stories/image-detection-cars ...\n",
      "3700, processing https://www.scotthyoung.com/blog/2025/01/13/what-i-learned-and-unlearned-reading-10-books-on-nutrition/ ...\n",
      "Processed 3700 articles, 83 articles left ...\n",
      "3703, processing https://mlops.systems/posts/2025-01-12-prompt-content-notes-on-chapter-6-prompt-engineering-for-llms.html ...\n",
      "3705, processing https://rubenerd.com/working-with-what-youve-got/ ...\n",
      "3706, processing https://pawelurbanek.com/rails-8-features ...\n",
      "3709, processing https://www.counting-stuff.com/labeling-things-by-hand-when-everyones-trying-not-to/ ...\n",
      "3713, processing https://www.maragu.dev/blog/running-llm-evals-right-next-to-your-code ...\n",
      "3714, processing https://vpetersson.com/2025/01/14/using-google-forms-for-waitlists.html ...\n",
      "3717, processing https://lukaspetersson.com/blog/2025/power-vertical/ ...\n",
      "3723, processing https://joeyehand.com/blog/2025/01/15/i-ditched-the-algorithm-for-rssand-you-should-too/ ...\n",
      "3730, processing https://michaeldrogalis.substack.com/p/what-i-wish-i-knew-before-i-quit ...\n",
      "3731, processing https://www.tomtunguz.com/presentations-with-ai/ ...\n",
      "3733, processing https://blog.railway.com/p/data-center-build-part-one ...\n",
      "3736, processing https://mtlynch.io/notes/emailing-me/ ...\n",
      "3739, processing https://medium.com/altitudehq/is-traditional-nlp-dead-05544ae7d756 ...\n",
      "3741, processing https://kellysutton.com/2025/01/18/moving-on-from-react-a-year-later.html ...\n",
      "3742, processing https://mlops.systems/posts/2025-01-17-final-notes-on-prompt-engineering-for-llms.html ...\n",
      "3743, processing https://mlops.systems/posts/2025-01-19-notes-on-ai-engineering-chapter-1.html ...\n",
      "3744, processing https://werd.io/2025/so-how-exactly-did-blogging-help-my-career ...\n",
      "3745, processing https://www.scotthyoung.com/blog/2025/01/19/do-something-big/ ...\n",
      "3746, processing https://www.erica.biz/2012/the-nastiest-habit/ ...\n",
      "3747, processing http://okayfail.com/2025/i-met-pg-once.html ...\n",
      "3748, processing https://shekhargulati.com/2025/01/19/how-good-are-llms-at-generating-functional-and-aesthetic-uis-an-experiment/ ...\n",
      "3749, processing https://ninkovic.dev/blog/2025/think-twice-before-using-github-actions ...\n",
      "3750, processing https://www.russ.cloud/2025/01/12/personal-project-updates-and-ai-editors/ ...\n",
      "Processed 3750 articles, 33 articles left ...\n",
      "3751, processing https://blog.rongarret.info/2025/01/i-am-not-failure-lessons-learned-from.html ...\n",
      "3752, processing https://nikkin.dev/blog/hosting-newsletter.html ...\n",
      "3753, processing https://www.ontestautomation.com/my-career-and-a-thought-experiment/ ...\n",
      "3754, processing https://twitter.com/x/migrate?tok=7b2265223a222f6a6f62657267756d2f7374617475732f31383831323532393730313339383831383834222c2274223a313733373338313736317d906ff5e42532e1262ad466b303876e5b ...\n",
      "3755, processing https://arslan.io/2025/01/20/four-years-at-planetscale/ ...\n",
      "3756, processing https://seankilleen.com/2025/01/my-new-reading-workflow/ ...\n",
      "3757, processing https://softwaredoug.com/blog/2025/01/19/llm-as-judge-both-ways.html ...\n",
      "3758, processing https://blog.rongarret.info/2025/01/i-am-not-failure-lessons-learned-from.html ...\n",
      "3759, processing https://seldo.com/posts/what-ive-learned-about-writing-ai-apps-so-far ...\n",
      "3760, processing http://rednafi.com/zephyr/domain_knowledge_dilemma/ ...\n",
      "3761, processing https://nmn.gl/blog/project-trends-ai ...\n",
      "3762, processing https://wilsoniumite.com/2025/01/21/weve-lost-our-respect-for-complexity/ ...\n",
      "3763, processing https://www.vincentschmalbach.com/startup-winter-hacker-news-lost-its-faith/ ...\n",
      "3764, processing https://www.alexmolas.com/2025/01/15/ipynb-for-llm.html ...\n",
      "3765, processing https://careersatdoordash.com/blog/overcome-the-cold-start-problem-in-menu-item-tagging/ ...\n",
      "3766, processing https://david.guillot.me/en/posts/tech/web-push-notifications-an-experiment/ ...\n",
      "3767, processing https://vickiboykis.com/2025/01/23/you-can-just-hack-on-atproto/ ...\n",
      "3768, processing https://simonwillison.net/2025/Jan/24/anthropics-new-citations-api/ ...\n",
      "3769, processing https://kill-the-newsletter.com/feeds/2fcxlwkf5kes7lrk/entries/11kmzcxeb0lx0ylf60s0.html ...\n",
      "3770, processing https://vpetersson.com/2025/01/22/how-i-use-home-assistant-in-2025.html ...\n",
      "3771, processing https://thebootstrappedfounder.com/building-systems-that-work-while-you-dont/ ...\n",
      "3772, processing https://shekhargulati.com/2025/01/18/can-claude-single-call-and-zero-shot-do-what-devin-cant-do/ ...\n",
      "3773, processing https://mertbulan.com/2025/01/26/once-you-are-laid-off-you-will-never-be-the-same-again/ ...\n",
      "3774, processing https://herbertlui.net/dont-worry-about-getting-chosen/ ...\n",
      "3775, processing https://simonwillison.net/2025/Jan/26/ai-models-are-now-very-good-historians/ ...\n",
      "3776, processing https://simonwillison.net/2025/Jan/26/ai-models-are-now-very-good-historians/ ...\n",
      "3777, processing https://dostoynikov.com/living-without-any-expectation-from-life/ ...\n",
      "3778, processing https://kellysutton.com/2025/01/25/letting-others-get-rich.html ...\n",
      "3779, processing https://nemo.foo/blog/day-4-of-an-afternoon-project ...\n",
      "3780, processing https://herbertlui.net/four-ways-to-reach-out-to-your-network-for-job-opportunities/ ...\n",
      "3781, processing https://twitter.com/x/migrate?tok=7b2265223a222f6a6f62657267756d2f7374617475732f31383833383838313938353037343939383738222c2274223a313733383035313739307d9a6bd7c381db27e94ead863888280c7e ...\n",
      "3782, processing https://binarysolo.blog/indie-saas-and-boring-tax-stuff/ ...\n"
     ]
    }
   ],
   "source": [
    "## slow, but less likely to get rate limited\n",
    "\n",
    "for i, item in enumerate(articles):\n",
    "    if item.text:\n",
    "        continue\n",
    "\n",
    "    print(f\"{i}, processing {item.resolved_url} ...\")\n",
    "\n",
    "    item.text = get_url_text(item.resolved_url, with_api_key=False)\n",
    "    articles_db.update(item.pocket_item_id, {\"text\": item.text})\n",
    "    if i % 50 == 0:\n",
    "        print(f\"Processed {i} articles, {len(articles) - i} articles left ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "## fast, but you'll get rate limited and should try again\n",
    "\n",
    "# def process_batch(items: list[tuple[int, object]], max_workers=10):\n",
    "#     with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "#         future_to_item = {\n",
    "#             executor.submit(get_url_text, item.resolved_url): (i, item)\n",
    "#             for i, item in items\n",
    "#         }\n",
    "\n",
    "#         for future in tqdm.tqdm(as_completed(future_to_item), total=len(items)):\n",
    "#             i, item = future_to_item[future]\n",
    "#             try:\n",
    "#                 item.text = future.result()\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing item {i}: {e}\")\n",
    "\n",
    "\n",
    "# items_with_index = [(i, item) for i, item in enumerate(pocket_items) if not item.text]\n",
    "# process_batch(items_with_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Google Gemini model with OpenAI Python SDK to summarize text into a few paragraphs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = OpenAI(\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n",
    "def summarize_text(text: str) -> str:\n",
    "    try:\n",
    "        completion = llm_client.chat.completions.create(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"Summarize the provided text in 2-5 paragraphs, maintaining the original author's first-person perspective and voice. The summary should read as if the original author wrote it themselves as a condensed version of their full text. Return the summary between <summary> and </summary> tags.\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": f\"<text>{text}</text>\"},\n",
    "            ],\n",
    "        )\n",
    "        summary = re.search(\n",
    "            r\"<summary>(.*?)</summary>\",\n",
    "            completion.choices[0].message.content,\n",
    "            re.DOTALL,\n",
    "        )\n",
    "        if summary:\n",
    "            return True, summary.group(1)\n",
    "        else:\n",
    "            return False, completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"summary error: {e}, sleeping for 30 seconds ...\")\n",
    "        time.sleep(30)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3119, processing https://longform.asmartbear.com/stealth-mode/ ...\n",
      "3695, processing https://data-people-group.github.io/blogs/2025/01/13/docwrangler/ ...\n",
      "3741, processing https://kellysutton.com/2025/01/18/moving-on-from-react-a-year-later.html ...\n",
      "3772, processing https://shekhargulati.com/2025/01/18/can-claude-single-call-and-zero-shot-do-what-devin-cant-do/ ...\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(articles):\n",
    "    if item.summary or item.summary_attempted_message:\n",
    "        continue\n",
    "\n",
    "    print(f\"{i}, processing {item.resolved_url} ...\")\n",
    "    success, message = summarize_text(item.text)\n",
    "    if success:\n",
    "        item.summary = message\n",
    "        articles_db.update(item.pocket_item_id, {\"summary\": item.summary})\n",
    "    else:\n",
    "        item.summary_attempted_message = message\n",
    "        articles_db.update(item.pocket_item_id, {\"summary_attempted_message\": item.summary_attempted_message})\n",
    "        \n",
    "    if i % 50 == 0:\n",
    "        print(f\"Processed {i} urls, {len(articles) - i} left ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
